[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LUNG CANCER SURVIVAL",
    "section": "",
    "text": "1 Introduction\n\n1.0.1 Why This Topic?\nOne of the most common and fatal types of cancer in the world is lung cancer. Lung cancer patients continue to have a poor survival rate despite advancements in medical technology and therapy, and much more has to be discovered about the variables affecting patient outcomes. Comprehending these variables can aid in directing therapy choices, enhancing patient outcomes, and influencing healthcare regulations.\nResearchers can examine the amount of time until a specific event, like death or the evolution of a disease, occurs by using survival analysis, a potent statistical method. We can learn more about how various characteristics, including age, gender, performance scores, and therapy kinds, affect survival times by using survival analysis to lung cancer data. This type of analysis could advance our knowledge of lung cancer and ultimately lead to better patient care.\n\n\n1.0.2 Questions of Interest\nThe following important questions are the focus of this project:\n1.⁠ ⁠Overall Survival Probability: How likely is it that patients with lung cancer will survive over time? 2.⁠ ⁠Effect of therapy and Demographics: How do therapy type, age, and gender impact lung cancer patients’ survival times? 3.⁠ ⁠Comparative Survival Analysis: What are the most important factors influencing survival outcomes, and how do survival curves vary among different groups?\n\n\n1.0.3 Context and Relevance\nDue to its high mortality rate, lung cancer affects millions of people globally and has a major influence on public health systems. Healthcare professionals can create more individualised treatment programs, distribute resources efficiently, and even enhance patients’ quality of life by looking at characteristics that affect survival.\nThis project’s data comes from clinical trials with people who have lung cancer, which offers a wealth of information for examining survival trends. We want to find significant insights that could advance the medical community’s comprehension of lung cancer outcomes by utilising statistical methods including Kaplan-Meier curves, Cox Proportional Hazards models, and forest plots.\n\n\n1.0.4 Significance of This Study\nBoth researchers and medical professionals can benefit from the study’s practical conclusions. Practitioners may be able to make more educated treatment decisions if they can identify the factors that have a substantial impact on survival times. This analysis also emphasises the significance of clinical and demographic aspects, providing a comprehensive perspective on the treatment of patients with lung cancer. The ultimate goal of this project is to assist with continued research aimed at raising the quality of life and survival rates for people with lung cancer.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description\nThe lung dataset from the R survival package is being used for this project. This dataset was carefully selected to examine survival outcomes in patients with lung cancer and is frequently used to illustrate survival analysis approaches.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "",
    "text": "2.1.1 Data Collection\nThe dataset was gathered from patients with lung cancer as part of an observational study or clinical trial. Researchers and medical professionals monitoring lung cancer patients over a predetermined time period may have captured the data.\n\n\n2.1.2 Format\nThe R software uses a data frame format for the lung dataset. Individual patients are represented by each row, while variables describing characteristics such as performance score, age, sex, censoring status, and survival time are represented by each column. It is a static dataset and does not receive regular updates.\n\n\n2.1.3 Dimensions\n\nRows: The dataset includes 228 observations (patients).\nColumns: There are 10 variables, which include:\n a. time: Survival time in days.\n b. status: Censoring status (1 if the event occurred, 0 if censored).\n c. age: Patient’s age in years.\n d. sex: Patient’s sex (1 = male, 2 = female).\n e. ph.ecog: ECOG performance score (0 = asymptomatic, 1 = symptomatic but ambulatory, 2 = bedridden &lt;50% of the time, etc.).\n f. ph.karno, pat.karno, meal.cal, wt.loss, etc.\n\n\n\n2.1.4 Potential Issues\n\nMissing Values: Some observations have missing data, particularly in variables like ph.karno (Karnofsky performance score), meal.cal (caloric intake), and wt.loss (weight loss).\nData Sparsity: As it’s a small dataset, detailed subgroup analysis may lack statistical power.\nData Encoding: Certain variables are encoded as numeric values (e.g., sex and status), requiring careful interpretation to avoid confusion.\n\n\n\n2.1.5 Data import\nThe dataset is part of the survival package in R and can be imported directly using the command data(lung) after loading the survival package. The code snippet for the same is shown below:\n\n\nCode\n# install.packages(\"survival\")\nlibrary(survival)\nsuppressWarnings(data(\"lung\")) # suppressing this warning, which shows up when we load the same data multiple time -&gt; irrelevant warning\nhead(lung)\n\n\n  inst time status age sex ph.ecog ph.karno pat.karno meal.cal wt.loss\n1    3  306      2  74   1       1       90       100     1175      NA\n2    3  455      2  68   1       0       90        90     1225      15\n3    3 1010      1  56   1       0       90        90       NA      15\n4    5  210      2  57   1       1       90        60     1150      11\n5    1  883      2  60   1       0      100        90       NA       0\n6   12 1022      1  74   1       1       50        80      513       0",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\n\n2.2.1 Overview of Missing Values\nThe lung dataset contains some missing values in specific variables. Understanding these missing values is essential as they can impact the accuracy of our survival analysis. To visualize the presence of missing values:\n\n\nCode\n# install.packages(\"ggplot2\")\n# install.packages(\"naniar\")\nlibrary(ggplot2)\nlibrary(naniar)\ngg_miss_var(lung)\n\n\n\n\n\n\n\n\n\nObservations:\n\nThe variable meal.cal has the highest number of missing values, with the line extending to the right side of the chart, indicating approximately 45 missing values.\nwt.loss has the second-highest number of missing values, followed by pat.karno.\nSome variables, like time, status, sex, and age, have no missing values (indicated by points at zero on the x-axis).\nVariables with shorter lines, such as ph.karno and ph.ecog, have fewer missing values, suggesting they have only a small portion of data missing.\n\n\n\n2.2.2 Patterns in Missing Values\nTo analyze the missing values, a heatmap or bar plot can show which variables have missing entries. Additionally, checking correlations between missing values can help understand if there is a pattern (e.g., if patients with high Karnofsky scores also have missing caloric intake). Below is a heatmap to show the distribution in the data:\n\n\nCode\n# install.packages(\"dplyr\")\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nmissing_data &lt;- lung |&gt; select(where(~ any(is.na(.))))\nmissing_corr &lt;- cor(is.na(missing_data) * 1, use = \"pairwise.complete.obs\")\n\nlibrary(reshape2)\nmelted_corr &lt;- melt(missing_corr)\nggplot(melted_corr, aes(x = Var1, y = Var2, fill = value)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\",\n                       midpoint = 0, limit = c(-1, 1), space = \"Lab\",\n                       name=\"Correlation\") +\n  theme_minimal() +\n  labs(title = \"Correlation of Missing Values\",\n       x = \"Variables\", y = \"Variables\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nObservations:\n\nMinimal or No Correlation Across Missing Values: Most of the cells in the heatmap are very light, close to white, indicating minimal to no correlation between missing values of different variables. This suggests that missing values in one variable do not strongly predict missing values in other variables.\nSlight Patterns: There are a few faint shades of color, especially between some pairs like ph.karno and meal.cal or ph.ecog and wt.loss, but these correlations are very weak, suggesting only a very slight pattern in the missing values.\nConclusion: Based on this heatmap, there does not appear to be a meaningful correlation pattern between the missing values across variables. This suggests that each variable’s missing data is likely random or independent of other variables in terms of missing values.\n\n\n\n2.2.3 Handling Missing Values\nThe strategies for handling missing data can be examined based on its distribution and importance:\n\nOmitting missing values: If the number of missing entries is small, we may exclude those cases.\nImputation: For critical variables with many missing values, we could consider mean, median, or mode imputation or more sophisticated techniques, like multiple imputation, if needed.\n\nGiven that this dataset is small, it is better to impute values, than omit the missing ones.\n\nFor numerical columns (ph.karno, meal.cal, wt.loss), we can use median imputation to preserve the distribution.\nFor categorical variables (if any, such as sex), we could impute using the mode (most frequent value).\n\nThe same is done below:\n\n\nCode\nlung &lt;- lung |&gt;\n  mutate(\n    ph.karno = ifelse(is.na(ph.karno), median(ph.karno, na.rm = TRUE), ph.karno),\n    meal.cal = ifelse(is.na(meal.cal), median(meal.cal, na.rm = TRUE), meal.cal),\n    wt.loss = ifelse(is.na(wt.loss), median(wt.loss, na.rm = TRUE), wt.loss)\n  )\n\nsummary(lung)\n\n\n      inst            time            status           age       \n Min.   : 1.00   Min.   :   5.0   Min.   :1.000   Min.   :39.00  \n 1st Qu.: 3.00   1st Qu.: 166.8   1st Qu.:1.000   1st Qu.:56.00  \n Median :11.00   Median : 255.5   Median :2.000   Median :63.00  \n Mean   :11.09   Mean   : 305.2   Mean   :1.724   Mean   :62.45  \n 3rd Qu.:16.00   3rd Qu.: 396.5   3rd Qu.:2.000   3rd Qu.:69.00  \n Max.   :33.00   Max.   :1022.0   Max.   :2.000   Max.   :82.00  \n NA's   :1                                                       \n      sex           ph.ecog          ph.karno        pat.karno     \n Min.   :1.000   Min.   :0.0000   Min.   : 50.00   Min.   : 30.00  \n 1st Qu.:1.000   1st Qu.:0.0000   1st Qu.: 77.50   1st Qu.: 70.00  \n Median :1.000   Median :1.0000   Median : 80.00   Median : 80.00  \n Mean   :1.395   Mean   :0.9515   Mean   : 81.93   Mean   : 79.96  \n 3rd Qu.:2.000   3rd Qu.:1.0000   3rd Qu.: 90.00   3rd Qu.: 90.00  \n Max.   :2.000   Max.   :3.0000   Max.   :100.00   Max.   :100.00  \n                 NA's   :1                         NA's   :3       \n    meal.cal         wt.loss       \n Min.   :  96.0   Min.   :-24.000  \n 1st Qu.: 768.0   1st Qu.:  0.000  \n Median : 975.0   Median :  7.000  \n Mean   : 938.3   Mean   :  9.658  \n 3rd Qu.:1075.0   3rd Qu.: 15.000  \n Max.   :2600.0   Max.   : 68.000  \n                                   \n\n\nAs shown above, the columns with higher missing values have been imputed successfully. There are three other columns, namely “inst”, “pat.karno”, and “ph.ecog” which have missing values. But the number of missing values is negligible. We will be dropping those rows. This is better to ensure that the integrity of the data is maintained, since we would not want to have too much bias by imputing for missing values. Code for the same is as shown below:\n\n\nCode\nlung_cleaned &lt;- lung |&gt;\n  filter(!is.na(inst), !is.na(pat.karno), !is.na(ph.ecog))\n\nsummary(lung_cleaned)\n\n\n      inst            time            status           age       \n Min.   : 1.00   Min.   :   5.0   Min.   :1.000   Min.   :39.00  \n 1st Qu.: 3.00   1st Qu.: 168.5   1st Qu.:1.000   1st Qu.:56.00  \n Median :11.00   Median : 266.0   Median :2.000   Median :63.00  \n Mean   :11.05   Mean   : 308.5   Mean   :1.717   Mean   :62.34  \n 3rd Qu.:16.00   3rd Qu.: 408.5   3rd Qu.:2.000   3rd Qu.:69.00  \n Max.   :33.00   Max.   :1022.0   Max.   :2.000   Max.   :82.00  \n      sex           ph.ecog          ph.karno        pat.karno  \n Min.   :1.000   Min.   :0.0000   Min.   : 50.00   Min.   : 30  \n 1st Qu.:1.000   1st Qu.:0.0000   1st Qu.: 80.00   1st Qu.: 70  \n Median :1.000   Median :1.0000   Median : 80.00   Median : 80  \n Mean   :1.399   Mean   :0.9417   Mean   : 82.24   Mean   : 80  \n 3rd Qu.:2.000   3rd Qu.:1.0000   3rd Qu.: 90.00   3rd Qu.: 90  \n Max.   :2.000   Max.   :3.0000   Max.   :100.00   Max.   :100  \n    meal.cal         wt.loss       \n Min.   :  96.0   Min.   :-24.000  \n 1st Qu.: 800.0   1st Qu.:  0.000  \n Median : 975.0   Median :  7.000  \n Mean   : 940.6   Mean   :  9.422  \n 3rd Qu.:1075.0   3rd Qu.: 15.000  \n Max.   :2600.0   Max.   : 68.000  \n\n\nAs seen above, there are no missing values in the dataset anymore.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  }
]